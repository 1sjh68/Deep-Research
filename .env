# --- API密钥与认证 (API Keys & Authentication) ---
# 请在此处填入您的API密钥。这些是必需的。
DEEPSEEK_API_KEY=
EMBEDDING_API_KEY=
GOOGLE_API_KEYS="A,B,C"
GOOGLE_CSE_IDS="A,B,C"
# --- API端点配置 (API Endpoint Configuration) ---
# 通常不需要修改这些URL，除非您使用私有部署或代理。
# (Usually, you don't need to modify these URLs unless you are using a private deployment or a proxy.)
DEEPSEEK_BASE_URL="https://api.deepseek.com/v1"
EMBEDDING_API_BASE_URL="https://ai.gitee.com/v1"

# --- 核心任务参数 (Core Task Parameters) ---
# 这是整个内容生成任务的核心问题。
# (This is the core problem statement for the content generation task.)
USER_PROBLEM="# 核心任务 (Core Task)
创作一篇关于相对论的深度探究文章。本文必须严格遵循“第一性原理”，引导读者完成一次从经典物理学大厦的根基，到其出现的裂痕，再到狭义相对论这座新大厦如何建立的完整思想旅程。

# 目标受众 (Target Audience)
本文的核心读者是已掌握高中或大学一年级物理学知识（熟悉牛顿力学、基础电磁学和微积分概念）的理工科学生或科学爱好者。他们对物理学有浓厚兴趣，追求严谨的逻辑推导，而不仅仅是科普知识的罗列。

# 核心方法论 (Core Methodology): “第一性原理”的演绎
文章的叙述必须遵循以下逻辑链条，层层递进，环环相扣：
1.  **奠定旧基石**：从经典物理的基石——伽利略相对性原理和牛顿的绝对时空观开始，构建读者熟悉的世界模型。
2.  **发现裂痕**：引入麦克斯韦方程组，详细阐述其预言的“真空光速c是宇宙常数”这一结论，如何与基于绝对时空观的“伽利略速度叠加法则”产生不可调和的尖锐矛盾。这是全文最重要的转折点。
3.  **建立新公设**：明确提出爱因斯坦为解决矛盾而提出的两条新的“第一性原理”——狭义相对性原理和光速不变原理。强调这是新理论的逻辑起点。
4.  **演绎新世界**：完全且仅仅基于以上两条新公设，通过清晰的思想实验（如光钟、高速运行的列车等）和概念推演，逻辑地导出狭义相对论颠覆性的结论，包括但不限于：同时性的相对性、时间膨胀、长度收缩、质能等价（E=mc²）的物理意义。
5.  **形成新框架**：最终说明洛伦兹变换是如何作为满足新公设的必然数学工具，取代伽利略变换，成为描述新时空观的数学框架。

# 内容范围与深度 (Scope & Depth)
- **主要焦点**：深入、详尽地阐述**狭义相对论**。
- **次要内容**：在文章末尾，可以简要提及狭义相对论的局限性（无法处理引力），并引出广义相对论的核心思想（如等效原理）作为展望，但不必深入展开。
- **数学要求**：推导过程应注重物理图像和逻辑的清晰性。可以出现公式，但应避免复杂的张量运算。目标是让读者理解“为什么”和“如何”推导出这些结论，而不是陷入数学细节。

# 语气与风格 (Tone & Style)
- **严谨的学者风范**：保持客观、严谨、逻辑清晰的学术风格。
- **出色的教育者口吻**：语言应精准但不晦涩，善于使用恰当的比喻和思想实验来化解复杂概念，仿佛一位物理学大师在亲自授课。
- **探究式叙事**：行文应带有强烈的引导性和探究感，不断设问、分析、解决矛盾，带领读者主动思考，而不是被动接收信息。"

# 指定用于提供额外上下文的本地文件列表，用逗号分隔。
# (Specify a comma-separated list of local files to provide additional context.)
EXTERNAL_FILES="C:/Users/oo/Desktop/书库/广义相对论引论_(俞允强)_(Z-Library).pdf"


# --- 模型选择 (Model Selection) ---
# 您可以为不同任务指定不同的AI模型。

# 主要内容生成模型：负责撰写报告中各个章节的核心文本内容。
MAIN_AI_MODEL="deepseek-reasoner"

# 重型/推理模型：用于处理需要复杂逻辑、深度推理或技术推导的特定章节。
MAIN_AI_MODEL_HEAVY="deepseek-reasoner"

# 评审与批判模型：负责分析已生成的内容，找出其中的缺陷、逻辑漏洞和待改进之处。
SECONDARY_AI_MODEL="deepseek-reasoner"

# 摘要生成模型：用于将长文本（如网页、外部资料、已完成章节）压缩成精炼的摘要。
SUMMARY_MODEL_NAME="deepseek-coder"

# 研究查询生成模型：根据知识空白（Knowledge Gaps），智能地生成用于网络搜索的精确查询词。
RESEARCHER_MODEL_NAME="deepseek-chat"

# 初始大纲生成模型：根据用户最初的问题，创建整个文档的结构化大纲（JSON格式）。
OUTLINE_MODEL_NAME="deepseek-coder"

# 规划审查与修正模型：在写作过程中，评估并修正剩余部分的写作大纲，确保计划的适应性。
PLANNING_REVIEW_MODEL_NAME="deepseek-coder"

# 最终润色与风格指导模型：负责对全文进行最后的通读和润色，并生成风格指南。
EDITORIAL_MODEL_NAME="deepseek-chat"

# JSON格式修复模型：当其他模型返回的JSON格式不正确时，调用此模型进行修复。
JSON_FIXER_MODEL_NAME="deepseek-coder"

# 文本嵌入模型：将文本块转换为向量，用于在向量数据库中进行存储和相似性检索（RAG的核心）。
EMBEDDING_MODEL_NAME="bge-m3"
# --- 执行流程控制 (Execution Flow Control) ---
# AI进行“生成-评审-修改”循环的最大次数。
# (The maximum number of "generate-review-revise" cycles for the AI.)
MAX_ITERATIONS=4

# 期望生成的文档总长度（字符数）。
# (The target total length of the document in characters.)
INITIAL_SOLUTION_TARGET_CHARS=15000

# 是否在关键步骤暂停并等待用户输入 (True/False)。
# (Whether to pause and wait for user input at critical steps.)
INTERACTIVE_MODE="False"

# 是否启用并行的网络抓取以进行研究 (True/False)。
# (Whether to enable parallel web scraping for research.)
USE_ASYNC_RESEARCH="True"

# 是否在生成过程中允许AI动态审查和修改剩余的大纲 (True/False)。
# (Whether to allow the AI to dynamically review and modify the remaining outline during generation.)
ENABLE_DYNAMIC_OUTLINE_CORRECTION="True"

# --- API与网络参数 (API & Network Parameters) ---
# API请求的超时时间（秒）。
# (Timeout for API requests in seconds.)
API_TIMEOUT_SECONDS=900

# API调用失败后的最大重试次数。
# (Maximum number of retries after a failed API call.)
API_RETRY_MAX_ATTEMPTS=3

# API重试等待时间的指数乘数。
# (The exponential multiplier for API retry wait time.)
API_RETRY_WAIT_MULTIPLIER=1

# API重试之间的最大等待秒数。
# (The maximum wait time in seconds between API retries.)
API_RETRY_MAX_WAIT=60

# --- 数据处理与RAG参数 (Data Processing & RAG Parameters) ---
# 生成内容时，每个文本块的最大Token数。
# (The maximum number of tokens for each text chunk during content generation.)
MAX_CHUNK_TOKENS=4096

# 连续文本块之间的重叠字符数。
# (The number of overlapping characters between consecutive text chunks.)
OVERLAP_CHARS=800

# 在一个章节/小节的生成中，最多创建的文本块数量。
# (The maximum number of text chunks to create for a single section/subsection.)
MAX_CHUNKS_PER_SECTION=20

# 进行网络研究时，每个搜索查询返回的结果数量。
# (The number of search results to return for each query during web research.)
NUM_SEARCH_RESULTS=3

# 针对单个知识空白，AI最多生成的搜索查询数量。
# (The maximum number of search queries the AI will generate for a single knowledge gap.)
MAX_QUERIES_PER_GAP=3

# --- 向量数据库 (ChromaDB) 参数 ---
# 向量数据库（经验库）的本地存储路径。
# (The local storage path for the vector database (experience store).)
VECTOR_DB_PATH="./chroma_db"

# 向量数据库中主集合的名称。
# (The name of the main collection in the vector database.)
VECTOR_DB_COLLECTION_NAME="experience_store"

# 在进行文本嵌入时，每批处理的文本数量。
# (The number of texts to process in each batch during embedding.)
EMBEDDING_BATCH_SIZE=32

# 从经验库中检索以供参考的过往经验数量。
# (The number of past experiences to retrieve from the store for context.)
NUM_RETRIEVED_EXPERIENCES=1